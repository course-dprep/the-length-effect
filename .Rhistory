dodge_PC_model_rotated <- principal (dodge_subset[, 3:32], nfactors=9, rotate="varimax")
dodge_PC_model_rotated_loadings <- loadings (dodge_PC_model_rotated)
print (dodge_PC_model_rotated_loadings, cutoff=0)
print (dodge_PC_model_rotated_loadings, cutoff=0.4)
pc9 <- principal (dodge_sub[, 3:32], nfactors=9, rotate="varimax")
print(1 - pc9Suniqueness)
print(1 - pc9$uniqueness)
pc9 <- principal (dodge_subset[, 3:32], nfactors=9, rotate="varimax")
print(1 - pc9$uniqueness)
print(round(1 - pc9$uniqueness), 3)
print (comm9)
print(round(1 - pc9$uniqueness), 3)
dodge_PC_model_rotated <- principal (dodge_subset[, 3:32], nfactors=9, rotate="varimax")
dodge_PC_model_rotated_loadings <- loadings (dodge_PC_model_rotated)
print (dodge_PC_model_rotated_loadings, cutoff=0)
print (dodge_PC_model_rotated_loadings, cutoff=0.4)
pc9 <- principal (dodge_subset[, 3:32], nfactors=9, rotate="varimax")
comm9 <- 1 - pc9$uniquenesses
# Print communalities nicely
print(round(comm9, 3))
dodge_PC_model_rotated <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
dodge_PC_model_rotated_loadings <- loadings (dodge_PC_model_rotated)
print (dodge_PC_model_rotated_loadings, cutoff=0)
print (dodge_PC_model_rotated_loadings, cutoff=0.4)
pc9 <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
comm9 <- 1 - pc9$uniquenesses
print(round(comm9, 3))
dodge_PC_model_rotated <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
dodge_PC_model_rotated_loadings <- loadings (dodge_PC_model_rotated)
print (dodge_PC_model_rotated_loadings, cutoff=0)
print (dodge_PC_model_rotated_loadings, cutoff=0.4)
pc9 <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
comm9 <- 1 - pc9$uniquenesses
print(round(comm9["V6"], 1))
dodge_PC_model_rotated <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
dodge_PC_model_rotated_loadings <- loadings (dodge_PC_model_rotated)
print (dodge_PC_model_rotated_loadings, cutoff=0)
print (dodge_PC_model_rotated_loadings, cutoff=0.4)
pc9 <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
comm9 <- 1 - pc9$uniquenesses
print(round(comm9, 1))
print(round(comm9, 3))
print(round(comm9, 3)*100)
dodge_M_rotated <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
dodge_M_rotated_load <- loadings (dodge_M_rotated)
print (dodge_M_rotated_load, cutoff=0)
print (dodge_M_rotated_load, cutoff=0.4)
pc9 <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
comm9 <- 1 - pc9$uniquenesses
print(round(comm9, 3)*100
dodge_M_rotated <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
# exercise 4
dodge_M_rotated <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
dodge_M_rotated_load <- loadings (dodge_M_rotated)
print (dodge_M_rotated_load, cutoff=0)
print (dodge_M_rotated_load, cutoff=0.4)
pc9 <- principal (dodge_subset[, 3:32], nfactors=5, rotate="varimax")
comm9 <- 1 - pc9$uniquenesses
print(round(comm9, 3)*100)
# exercise 5
View(dodge_M_rotated_load)
View(pc9)
print(dodge_M_rotated_load, cutoff = 0.4)
pc5 <- principal(dodge_subset[, 3:32], nfactors = 5, rotate = "varimax", scores = TRUE)
reg_data <- data.frame(
V1 = dodge_subset$V1__purchase_intentions,
pc5$scores
)
fit <- lm(V1 ~ ., data = reg_data)
summary(fit)
ex6<- principal(dodge_subset[, 3:32], nfactors = 5, rotate = "varimax", scores = TRUE)
reg_data <- data.frame(
V1 = dodge_subset$V1__purchase_intentions,
ex6$scores
)
fit <- lm(V1 ~ ., data = reg_data)
summary(fit)
knitr::opts_chunk$set(
echo    = FALSE,
message = FALSE,
warning = FALSE,
fig.align = "center",
fig.width = 7, fig.height = 4, dpi = 180
)
options(tidyverse.quiet = TRUE)
# Load IMDb title.basics data
title.basics <- fread("https://datasets.imdbws.com/title.basics.tsv.gz")
knitr::opts_chunk$set(
echo    = FALSE,
message = FALSE,
warning = FALSE,
fig.align = "center",
fig.width = 7, fig.height = 4, dpi = 180
)
options(tidyverse.quiet = TRUE)
need_pkgs <- c(
"tidyverse","data.table","readr","lubridate",
"knitr","kableExtra","broom"
)
# Optional (used only if you later add those features)
opt_pkgs <- c("ISOweek","zoo","janitor","gt")
missing <- setdiff(need_pkgs, rownames(installed.packages()))
if (length(missing)) {
stop(
sprintf("Please install missing packages before knitting: %s",
paste(missing, collapse = ", "))
)
}
invisible(lapply(need_pkgs, library, character.only = TRUE))
present_opt <- intersect(opt_pkgs, rownames(installed.packages()))
if (length(present_opt)) {
invisible(lapply(present_opt, library, character.only = TRUE))
}
summary(cars)
# Load IMDb title.basics data
title.basics <- fread("https://datasets.imdbws.com/title.basics.tsv.gz")
# Load IMDb title.ratings data
title.ratings <- fread("https://datasets.imdbws.com/title.ratings.tsv.gz")
str(title.ratings)
# Load IMDb title.basics data
title.basics <- fread("https://datasets.imdbws.com/title.basics.tsv.gz")
str(title.basics)
# Summary of title.basics
dim(title.basics)
nrow(title.basics)
ncol(title.basics)
colnames(title.basics)
str(title.basics)
summary(title.basics)
head(title.basics, 10)
# Summary of title.ratings
dim(title.ratings)
nrow(title.ratings)
ncol(title.ratings)
colnames(title.ratings)
str(title.ratings)
summary(title.ratings)
head(title.ratings, 10)
# Complete summary title.basics & title.ratings
summary_tb1 <- tibble::tibble(
dataset = c("title.basics","title.ratings"),
n_rows  = c(nrow(title.basics), nrow(title.ratings)),
n_cols  = c(ncol(title.basics), ncol(title.ratings)))
knitr::kable(summary_tb1, caption = "Data size summary") |>
kableExtra::kable_styling(full_width = FALSE,
bootstrap_options = c("striped","hover","condensed"))
# checking the variable type
str(title.basics)                 # compact overview
dplyr::glimpse(title.basics)      # tidyverse overview
sapply(title.basics, class)       # class of each column
sapply(title.basics, typeof)      # storage type of each column
str(title.ratings)                 # compact overview
dplyr::glimpse(title.ratings)      # tidyverse overview
sapply(title.ratings, class)       # class of each column
sapply(title.ratings, typeof)      # storage type of each column
# checking the variable type
str(title.basics)                 # compact overview
dplyr::glimpse(title.basics)      # tidyverse overview
sapply(title.basics, class)       # class of each column
sapply(title.basics, typeof)      # storage type of each column
str(title.ratings)                 # compact overview
dplyr::glimpse(title.ratings)      # tidyverse overview
sapply(title.ratings, class)       # class of each column
sapply(title.ratings, typeof)      # storage type of each column
# changing character for numerical and change \N for NA
to_na <- function(x) {
y <- as.character(x)
y[y %in% c("\\N", "N", "")] <- NA_character_
y
}
#Cleaning the titile.basics
title.basics_clean <- title.basics %>%
mutate(
titleType      = to_na(titleType),
primaryTitle   = to_na(primaryTitle),
startYear      = to_na(startYear),
runtimeMinutes = to_na(runtimeMinutes)) %>%
mutate(
startYear      = suppressWarnings(as.integer(startYear)),
runtimeMinutes = suppressWarnings(as.numeric(runtimeMinutes))) %>%
select(tconst, titleType, primaryTitle, originalTitle, isAdult, startYear, endYear, runtimeMinutes, genres) %>%
distinct(tconst, .keep_all = TRUE)
#Cleaning the title.ratings
title.ratings_clean <- title.ratings %>%
mutate(
averageRating = to_na(averageRating),
numVotes      = to_na(numVotes)) %>%
mutate(averageRating = as.numeric(averageRating),
numVotes      = as.integer(numVotes)) %>%
select(tconst, averageRating, numVotes) %>%
distinct(tconst, .keep_all = TRUE)
# Checking again the variable type correct
str(title.basics_clean)                 # compact overview
dplyr::glimpse(title.basics_clean)      # tidyverse overview
sapply(title.basics_clean, class)       # class of each column
sapply(title.basics_clean, typeof)
# Variable table:
var_dict <- tribble(
~Variable,        ~Date_Class,      ~Definition,                                                        ~Role,
"runtimeMinutes", "numeric",  "Duration of the movie in minutes",                                 "Independent variable",
"averageRating",  "numeric",   "Average IMDb user rating (0â€“10 scale, aggregated from user votes)", "Dependent variable",
"startYear",      "numeric",  "Year the movie was released",                                      "Control variable")
var_dict %>%
gt() %>%
tab_header(title = "Table 1. Variable Explanation") %>%
tab_options(column_labels.font.weight = "bold")
# checking outliers in averageRating - histogram
ratings_clean <- dplyr::filter(title.ratings, !is.na(averageRating))
ggplot(ratings_clean, aes(x = averageRating)) +
geom_histogram(binwidth = 0.25, color = "white", fill = "grey30", boundary = 0) +
scale_x_continuous(limits = c(0, 10), breaks = 0:10) +
labs(x = "Average rating", y = "Count", title = "Average Rating IMDb") +
theme_minimal(base_size = 14)
install.packages("checkmate")   # run once in the Console
library(checkmate)
# allow NAs, but every non-NA must be within [0, 10]
assert_numeric(
title.ratings$averageRating,
lower = 0, upper = 10,
any.missing = TRUE,  # NAs allowed
all.missing = FALSE  # not all NA
)
# Filter for movies only
title.basics_clean <- title.basics %>%
filter(titleType == "movie") %>%
select(tconst, primaryTitle, startYear, runtimeMinutes) %>%
distinct(tconst, .keep_all = TRUE)
# Renaming
title.basics_clean <- title.basics_clean %>%
rename(
title           = primaryTitle,
start_year      = startYear,
runtime_minutes = runtimeMinutes)
title.ratings_clean <- title.ratings_clean %>%
rename(
average_rating  = averageRating,
votes           = numVotes
)
# Set filter data and movie duration
title.basics_clean <- title.basics_clean %>%
filter(runtime_minutes > 0,
runtime_minutes <= 300) %>%
filter(start_year <= 2025)
# Set filter data and movie duration
title.basics_clean <- title.basics_clean %>%
filter(runtime_minutes > 0,
runtime_minutes <= 300) %>%
filter(start_year <= 2025)
# Merging datasets
merged_data <- title.basics_clean %>%
select(tconst, runtime_minutes, start_year, title) %>%
mutate(
runtime_minutes = suppressWarnings(as.numeric(runtime_minutes)),
start_year      = suppressWarnings(as.integer(start_year)),
title = suppressWarnings(as.character(title))
) %>%
inner_join(
title.ratings_clean %>% select(tconst, average_rating, votes),
by = "tconst"
) %>%
mutate(
average_rating = as.numeric(average_rating),
votes= as.integer(votes)
)
merged_data <- merged_data %>%
filter(runtime_minutes > 0,
runtime_minutes <= 300) %>%
filter(start_year <= 2025)
# Filter for movies only
title.basics_clean <- title.basics %>%
filter(titleType == "movie") %>%
select(tconst, primaryTitle, startYear, runtimeMinutes) %>%
distinct(tconst, .keep_all = TRUE)
# Renaming
title.basics_clean <- title.basics_clean %>%
rename(
title           = primaryTitle,
start_year      = startYear,
runtime_minutes = runtimeMinutes)
title.ratings_clean <- title.ratings_clean %>%
rename(
average_rating  = averageRating,
votes           = numVotes
)
View(title.ratings_clean)
# Filter for movies only
title.basics_clean <- title.basics %>%
filter(titleType == "movie") %>%
select(tconst, primaryTitle, startYear, runtimeMinutes) %>%
distinct(tconst, .keep_all = TRUE)
# Renaming
title.basics_clean <- title.basics_clean %>%
rename(
title           = primaryTitle,
start_year      = startYear,
runtime_minutes = runtimeMinutes)
title.ratings_clean <- title.ratings_clean %>%
rename(
average_rating  = averageRating,
votes           = numVotes
)
View(title.basics_clean)
# Filter for movies only
title.basics_clean <- title.basics %>%
filter(titleType == "movie") %>%
select(tconst, primaryTitle, startYear, runtimeMinutes) %>%
distinct(tconst, .keep_all = TRUE)
# Renaming
title.basics_clean <- title.basics_clean %>%
rename(
title           = primaryTitle,
start_year      = startYear,
runtime_minutes = runtimeMinutes)
title.ratings_clean <- title.ratings_clean %>%
rename(
average_rating  = averageRating,
votes           = numVotes)
View(title.basics)
View(title.basics)
View(title.basics)
View(title.basics)
View(title.ratings_clean)
View(title.ratings)
# Set filter data and movie duration
title.basics_clean <- title.basics_clean %>%
filter(runtime_minutes > 0,
runtime_minutes <= 300) %>%
filter(start_year <= 2025)
# Merging datasets
merged_data <- title.basics_clean %>%
select(tconst, runtime_minutes, start_year, title) %>%
mutate(
runtime_minutes = suppressWarnings(as.numeric(runtime_minutes)),
start_year      = suppressWarnings(as.integer(start_year)),
title = suppressWarnings(as.character(title))
) %>%
inner_join(
title.ratings_clean %>% select(tconst, average_rating, votes),
by = "tconst"
) %>%
mutate(
average_rating = as.numeric(average_rating),
votes= as.integer(votes)
)
merged_data <- merged_data %>%
filter(runtime_minutes > 0,
runtime_minutes <= 300) %>%
filter(start_year <= 2025)
descriptives <- tibble(
Variable = c("runtime_minutes","average_rating","start_year"),
N        = c(sum(!is.na(merged_data$runtime_minutes)),
sum(!is.na(merged_data$average_rating)),
sum(!is.na(merged_data$start_year))),
Missing  = c(sum(is.na(merged_data$runtime_minutes)),
sum(is.na(merged_data$average_rating)),
sum(is.na(merged_data$start_year))),
Mean     = c(mean(merged_data$runtime_minutes, na.rm = TRUE),
mean(merged_data$average_rating,  na.rm = TRUE),
mean(merged_data$start_year,      na.rm = TRUE)),
SD       = c(sd(merged_data$runtime_minutes, na.rm = TRUE),
sd(merged_data$average_rating,  na.rm = TRUE),
sd(merged_data$start_year,      na.rm = TRUE)),
Min      = c(min(merged_data$runtime_minutes, na.rm = TRUE),
min(merged_data$average_rating,  na.rm = TRUE),
min(merged_data$start_year,      na.rm = TRUE)),
Max      = c(max(merged_data$runtime_minutes, na.rm = TRUE),
max(merged_data$average_rating,  na.rm = TRUE),
max(merged_data$start_year,      na.rm = TRUE)))
descriptives %>%
gt() %>%
tab_header(title = "Table 2. Descriptive Statistics") %>%
tab_options(column_labels.font.weight="bold")
descriptives <- tibble(
Variable = c("runtime_minutes","average_rating","start_year"),
N        = c(sum(!is.na(merged_data$runtime_minutes)),
sum(!is.na(merged_data$average_rating)),
sum(!is.na(merged_data$start_year))),
Missing  = c(sum(is.na(merged_data$runtime_minutes)),
sum(is.na(merged_data$average_rating)),
sum(is.na(merged_data$start_year))),
Mean     = c(mean(merged_data$runtime_minutes, na.rm = TRUE),
mean(merged_data$average_rating,  na.rm = TRUE),
mean(merged_data$start_year,      na.rm = TRUE)),
SD       = c(sd(merged_data$runtime_minutes, na.rm = TRUE),
sd(merged_data$average_rating,  na.rm = TRUE),
sd(merged_data$start_year,      na.rm = TRUE)),
Min      = c(min(merged_data$runtime_minutes, na.rm = TRUE),
min(merged_data$average_rating,  na.rm = TRUE),
min(merged_data$start_year,      na.rm = TRUE)),
Max      = c(max(merged_data$runtime_minutes, na.rm = TRUE),
max(merged_data$average_rating,  na.rm = TRUE),
max(merged_data$start_year,      na.rm = TRUE)))
descriptives %>%
gt() %>%
tab_header(title = "Table 2. Descriptive Statistics") %>%
tab_options(column_labels.font.weight="bold")
# Checking the duplicated data
library(dplyr)
keys <- c("title", "start_year", "runtime_minutes")
movies_dup <- merged_data %>% as_tibble()
sum( duplicated(select(movies_dup, all_of(keys))) )
dups_rows <- movies_dup %>%
mutate(.is_dup = duplicated(select(., all_of(keys))) |
duplicated(select(., all_of(keys)), fromLast = TRUE)) %>%
filter(.is_dup) %>%
select(-.is_dup)
dup_groups <- movies_dup %>%
count(across(all_of(keys)), sort = TRUE) %>%
filter(n > 1)
dups_rows %>% slice_head(n = 80)
dup_groups %>% slice_head(n = 40)
# Dropping duplicated data
movies_final_clean <- movies_dup %>%
group_by(across(all_of(keys))) %>%
slice_max(votes, with_ties = FALSE) %>%
ungroup()
# How many rows were removed?
dropped <- nrow(movies_dup) - nrow(movies_final_clean)
dropped
# Sanity check: no duplicates remain
stopifnot(!any(duplicated(select(movies_final_clean, all_of(keys)))))
# Handling missing data
movies_final_no_na <- movies_final_clean %>%
filter(!is.na(runtime_minutes),
!is.na(average_rating),
!is.na(start_year),
!is.na(title))
# drop NA in those columns - chat
movies_final_no_na <- tidyr::drop_na(movies_final_clean, runtime_minutes, average_rating, start_year, title)
# or
movies_final_no_na <- movies_final_clean %>%
filter(!if_any(c(runtime_minutes, average_rating, start_year, title), is.na))
n_removed <- nrow(movies_final_clean) - nrow(movies_final_no_na)
n_removed
# Analysis, linear regression
LR1 <- lm(average_rating ~ runtime_minutes + start_year, data = movies_final_clean)
summary(LR1)
install.packages(c("modelsummary", "sandwich", "lmtest", "broom"))
library(modelsummary)
library(sandwich)
m_lin <- lm(average_rating ~ runtime_minutes + start_year, data = movies_final_clean)
VHC3 <- sandwich::vcovHC(m_lin, type = "HC3")
msummary(
m_lin,
vcov = VHC3,
stars = TRUE,
coef_map = c(
"(Intercept)"    = "Intercept",
"runtime_minutes" = "Runtime (minutes)",
"start_year"      = "Release year"
),
gof_omit = "IC|AIC|BIC",
title = "OLS: Audience rating on runtime, controlling for release year (HC3 SE)"
)
install.packages(c("modelsummary", "sandwich", "lmtest", "broom"))
library(ggplot2)
p1 <- ggplot(movies_final_clean, aes(x = runtime_minutes, y = average_rating)) +
geom_point(alpha = 0.15) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Ratings vs Runtime", x = "Runtime (minutes)", y = "Average rating") +
theme_minimal(base_size = 12)
p1
p2 <- ggplot(movies_final_clean, aes(x = start_year, y = average_rating)) +
geom_point(alpha = 0.15) +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Ratings vs Release Year", x = "Release year", y = "Average rating") +
theme_minimal(base_size = 12)
p2
# On the exact data you used for the plot:
with(movies_final_clean, c(
n_total = length(runtime_minutes),
n_lt100 = sum(runtime_minutes < 100, na.rm = TRUE),
min_runtime = min(runtime_minutes, na.rm = TRUE),
quantiles = paste(quantile(runtime_minutes, c(.01,.1,.25,.5,.75,.9,.99), na.rm=TRUE), collapse=", ")
))
knitr::opts_chunk$set(
echo    = FALSE,
message = FALSE,
warning = FALSE,
fig.align = "center",
fig.width = 7, fig.height = 4, dpi = 180
)
options(tidyverse.quiet = TRUE)
## Data Loading
# Load IMDb title.basics data
title.basics <- fread("https://datasets.imdbws.com/title.basics.tsv.gz")
need_pkgs <- c(
"tidyverse","data.table","readr","lubridate",
"knitr","kableExtra","broom"
)
# Optional (used only if you later add those features)
opt_pkgs <- c("ISOweek","zoo","janitor","gt")
missing <- setdiff(need_pkgs, rownames(installed.packages()))
if (length(missing)) {
stop(
sprintf("Please install missing packages before knitting: %s",
paste(missing, collapse = ", "))
)
}
invisible(lapply(need_pkgs, library, character.only = TRUE))
present_opt <- intersect(opt_pkgs, rownames(installed.packages()))
if (length(present_opt)) {
invisible(lapply(present_opt, library, character.only = TRUE))
}
## Data Loading
# Load IMDb title.basics data
title.basics <- fread("https://datasets.imdbws.com/title.basics.tsv.gz")
# Load IMDb title.ratings data
title.ratings <- fread("https://datasets.imdbws.com/title.ratings.tsv.gz")
setwd("C:/Users/Simona Borisova/AppData/Local/Microsoft/Windows/INetCache/IE/A7ZVOX89")
setwd("C:/Users/Simona Borisova/AppData/Local/Microsoft/Windows/INetCache/IE/A7ZVOX89")
git pull
